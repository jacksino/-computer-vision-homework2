{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x.view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(LeNet5, self).__init__()\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\tReshape(),\n",
    "\n",
    "\t\t\t# CONV1, ReLU1, POOL1\n",
    "\t\t\tnn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "\t\t\t# nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\t\t\t# CONV2, ReLU2, POOL2\n",
    "\t\t\tnn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Flatten(),\n",
    "\n",
    "\t\t\t# FC1\n",
    "\t\t\tnn.Linear(in_features=16 * 5 * 5, out_features=120),\n",
    "\t\t\tnn.ReLU(),\n",
    "\n",
    "\t\t\t# FC2\n",
    "\t\t\tnn.Linear(in_features=120, out_features=84),\n",
    "\t\t\tnn.ReLU(),\n",
    "\n",
    "\t\t\t# FC3\n",
    "\t\t\tnn.Linear(in_features=84, out_features=10)\n",
    "\t\t)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tlogits = self.net(x)\n",
    "\t\treturn logits\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "EPOCH1\tloss: 0.660427\tTest Error: Accuracy: 69.6%, Average loss: 0.894932\n",
      "\n",
      "EPOCH2\tloss: 0.277688\tTest Error: Accuracy: 86.5%, Average loss: 0.422568\n",
      "\n",
      "EPOCH3\tloss: 0.092691\tTest Error: Accuracy: 91.1%, Average loss: 0.287984\n",
      "\n",
      "EPOCH4\tloss: 0.053176\tTest Error: Accuracy: 92.8%, Average loss: 0.232429\n",
      "\n",
      "EPOCH5\tloss: 0.030145\tTest Error: Accuracy: 93.6%, Average loss: 0.203683\n",
      "\n",
      "EPOCH6\tloss: 0.029470\tTest Error: Accuracy: 95.1%, Average loss: 0.155091\n",
      "\n",
      "EPOCH7\tloss: 0.019340\tTest Error: Accuracy: 96.0%, Average loss: 0.127239\n",
      "\n",
      "EPOCH8\tloss: 0.014191\tTest Error: Accuracy: 96.7%, Average loss: 0.108613\n",
      "\n",
      "EPOCH9\tloss: 0.010716\tTest Error: Accuracy: 97.1%, Average loss: 0.095264\n",
      "\n",
      "EPOCH10\tloss: 0.007580\tTest Error: Accuracy: 97.4%, Average loss: 0.084857\n",
      "\n",
      "EPOCH11\tloss: 0.005558\tTest Error: Accuracy: 97.6%, Average loss: 0.076358\n",
      "\n",
      "EPOCH12\tloss: 0.004220\tTest Error: Accuracy: 97.8%, Average loss: 0.069452\n",
      "\n",
      "EPOCH13\tloss: 0.003318\tTest Error: Accuracy: 98.0%, Average loss: 0.062763\n",
      "\n",
      "EPOCH14\tloss: 0.002718\tTest Error: Accuracy: 98.2%, Average loss: 0.057304\n",
      "\n",
      "EPOCH15\tloss: 0.002492\tTest Error: Accuracy: 98.4%, Average loss: 0.051802\n",
      "\n",
      "EPOCH16\tloss: 0.002314\tTest Error: Accuracy: 98.6%, Average loss: 0.047270\n",
      "\n",
      "EPOCH17\tloss: 0.002135\tTest Error: Accuracy: 98.7%, Average loss: 0.043012\n",
      "\n",
      "EPOCH18\tloss: 0.002032\tTest Error: Accuracy: 98.7%, Average loss: 0.040071\n",
      "\n",
      "EPOCH19\tloss: 0.001851\tTest Error: Accuracy: 98.8%, Average loss: 0.037588\n",
      "\n",
      "EPOCH20\tloss: 0.001444\tTest Error: Accuracy: 98.9%, Average loss: 0.034569\n",
      "\n",
      "Saved PyTorch LeNet5 State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# DATASET\n",
    "train_data = datasets.MNIST(\n",
    "\troot='./data',\n",
    "\ttrain=False,\n",
    "\tdownload=True,\n",
    "\ttransform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "\troot='./data',\n",
    "\ttrain=False,\n",
    "\tdownload=True,\n",
    "\ttransform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "# PREPROCESS\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size)\n",
    "for X, y in train_dataloader:\n",
    "\tprint(X.shape)\t\t# torch.Size([256, 1, 28, 28])\n",
    "\tprint(y.shape)\t\t# torch.Size([256])\n",
    "\tbreak\n",
    "\n",
    "\n",
    "# MODEL\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = LeNet5().to(device)\n",
    "\n",
    "\n",
    "# TRAIN MODEL\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters())\n",
    "\n",
    "def train(dataloader, model, loss_func, optimizer, epoch):\n",
    "\tmodel.train()\n",
    "\tdata_size = len(dataloader.dataset)\n",
    "\tfor batch, (X, y) in enumerate(dataloader):\n",
    "\t\tX, y = X.to(device), y.to(device)\n",
    "\n",
    "\t\ty_hat = model(X)\n",
    "\t\tloss = loss_func(y_hat, y)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\tloss, current = loss.item(), batch * len(X)\n",
    "\tprint(f'EPOCH{epoch+1}\\tloss: {loss:>7f}', end='\\t')\n",
    "\n",
    "\n",
    "# Test model\n",
    "def test(dataloader, model, loss_fn):\n",
    "\tsize = len(dataloader.dataset)\n",
    "\tnum_batches = len(dataloader)\n",
    "\tmodel.eval()\n",
    "\ttest_loss, correct = 0, 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor X, y in dataloader:\n",
    "\t\t\tX, y = X.to(device), y.to(device)\n",
    "\t\t\tpred = model(X)\n",
    "\t\t\ttest_loss += loss_fn(pred, y).item()\n",
    "\t\t\tcorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\ttest_loss /= num_batches\n",
    "\tcorrect /= size\n",
    "\tprint(f'Test Error: Accuracy: {(100 * correct):>0.1f}%, Average loss: {test_loss:>8f}\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tepoches = 20\n",
    "\tfor epoch in range(epoches):\n",
    "\t\ttrain(train_dataloader, model, loss_func, optimizer, epoch)\n",
    "\t\ttest(test_dataloader, model, loss_func)\n",
    "\n",
    "\t# Save models\n",
    "\ttorch.save(model.state_dict(), 'model.pth')\n",
    "\tprint('Saved PyTorch LeNet5 State to model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}